# SPDX-License-Identifier: MIT
# GPT-2 Transformer Model Configuration

menu "GPT-2 Configuration"

choice
	prompt "GPT-2 Model Size"
	default GPT2_MODEL_124M
	help
	  Select the GPT-2 model size to use.
	  Larger models have better performance but require more memory.

config GPT2_MODEL_124M
	bool "GPT-2 124M (base) - RECOMMENDED"
	help
	  Base GPT-2 model with 124M parameters.
	  12 layers, 12 heads, 768 embedding dimension.
	  System RAM: 8-16 GB required for loading
	  GPU Memory: ~4-8 GB for training (batch size dependent)

config GPT2_MODEL_350M
	bool "GPT-2 350M (medium) - REQUIRES 32GB+ SYSTEM RAM"
	help
	  Medium GPT-2 model with 350M parameters.
	  24 layers, 16 heads, 1024 embedding dimension.
	  WARNING: Requires 32-64 GB system RAM for loading!
	  GPU Memory: ~8-16 GB for training

config GPT2_MODEL_774M
	bool "GPT-2 774M (large) - REQUIRES 64GB+ SYSTEM RAM"
	help
	  Large GPT-2 model with 774M parameters.
	  36 layers, 20 heads, 1280 embedding dimension.
	  WARNING: Requires 64-128 GB system RAM for loading!
	  GPU Memory: ~16-24 GB for training

config GPT2_MODEL_1558M
	bool "GPT-2 1.5B (xl) - REQUIRES 128GB+ SYSTEM RAM"
	help
	  Extra large GPT-2 model with 1.5B parameters.
	  48 layers, 25 heads, 1600 embedding dimension.
	  WARNING: Requires 128+ GB system RAM for loading!
	  GPU Memory: ~24-40 GB for training

endchoice

config GPT2_MODEL_NAME
	string
	default "gpt2" if GPT2_MODEL_124M
	default "gpt2-medium" if GPT2_MODEL_350M
	default "gpt2-large" if GPT2_MODEL_774M
	default "gpt2-xl" if GPT2_MODEL_1558M

# Dataset selection
choice
	prompt "Training Dataset"
	default GPT2_DATASET_TINYSTORIES if GPT2_KV_TYING
	default GPT2_DATASET_SHAKESPEARE
	help
	  Select the dataset to use for training GPT-2.

config GPT2_DATASET_SHAKESPEARE
	bool "Shakespeare (tiny)"
	help
	  Tiny Shakespeare dataset (~1MB of text).
	  Good for testing and development.
	  ~300K training tokens, ~36K validation tokens.

config GPT2_DATASET_FINEWEBEDU
	bool "FineWebEdu"
	help
	  FineWebEdu dataset - educational web content.
	  High-quality filtered educational text.
	  Requires downloading and preprocessing.

config GPT2_DATASET_OPENWEBTEXT
	bool "OpenWebText"
	help
	  OpenWebText dataset - replication of GPT-2's WebText.
	  Large-scale web scrape dataset.
	  Requires significant storage and preprocessing.

config GPT2_DATASET_TINYSTORIES
	bool "TinyStories"
	help
	  TinyStories dataset - synthetic stories for small models.
	  High-quality GPT-3.5/GPT-4 generated stories with simple
	  vocabulary suitable for smaller language models.
	  See: https://github.com/Activated-AI/tinystories-quickstart
	  Compact dataset good for ablation studies and testing.

config GPT2_DATASET_CUSTOM
	bool "Custom dataset"
	help
	  Use a custom dataset.
	  Specify path to preprocessed .bin files.

endchoice

config GPT2_DATASET_NAME
	string
	default "shakespeare" if GPT2_DATASET_SHAKESPEARE
	default "finewebedu" if GPT2_DATASET_FINEWEBEDU
	default "openwebtext" if GPT2_DATASET_OPENWEBTEXT
	default "tinystories" if GPT2_DATASET_TINYSTORIES
	default "custom" if GPT2_DATASET_CUSTOM

config GPT2_CUSTOM_DATASET_PATH
	string "Custom dataset path"
	depends on GPT2_DATASET_CUSTOM
	default "data/custom"
	help
	  Path to directory containing train.bin and val.bin files.

# Training hyperparameters
config GPT2_BLOCK_SIZE
	int "Context length (block size)"
	default 1024
	range 128 2048
	help
	  Maximum sequence length for training.
	  Must be less than or equal to model's maximum (1024 for GPT-2).

config GPT2_GRADIENT_ACCUMULATION
	int "Gradient accumulation steps"
	default 1
	range 1 128
	help
	  Number of gradient accumulation steps.
	  Effective batch size = batch_size * gradient_accumulation_steps.
	  Use higher values to simulate larger batch sizes on limited GPU memory.

config GPT2_EVAL_INTERVAL
	int "Evaluation interval (steps)"
	default 100
	range 10 10000
	help
	  Evaluate model every N training steps.

config GPT2_EVAL_SAMPLES
	int "Evaluation samples"
	default 200
	range 10 10000
	help
	  Number of samples to use for evaluation.

config GPT2_WARMUP_STEPS
	int "Learning rate warmup steps"
	default 100
	range 0 10000
	help
	  Number of warmup steps for learning rate schedule.
	  0 disables warmup.

config GPT2_DECAY_LR
	bool "Enable learning rate decay"
	default y
	help
	  Use cosine learning rate decay schedule.

config GPT2_MIN_LR
	string "Minimum learning rate"
	default "6e-5"
	depends on GPT2_DECAY_LR
	help
	  Minimum learning rate for cosine decay.
	  Typically 1/10th of max learning rate.

config GPT2_MAX_ITERS
	int "Maximum training iterations"
	default 10000
	range 100 1000000
	help
	  Maximum number of training iterations.
	  For FineWebEdu: 50000 iterations is typical for baseline.
	  For Shakespeare: 5000-10000 iterations is sufficient.
	  Ignored if GPT2_MAX_TIME is set (time-based training).

config GPT2_MAX_TIME
	int "Maximum training time (seconds)"
	default 0
	range 0 86400
	help
	  Maximum training time in seconds (time-based training).
	  When set to non-zero, training stops when this time limit is reached,
	  regardless of iteration count. This provides more consistent training
	  duration across different hardware configurations.

	  Common values:
	    - 1800 (30 minutes) for quick tests
	    - 7200 (2 hours) for quality comparisons
	    - 28800 (8 hours) for production validation

	  Set to 0 to disable time-based limits (use MAX_ITERS instead).
	  When both MAX_TIME and MAX_ITERS are set, training stops when
	  EITHER limit is reached.

config GPT2_LOG_INTERVAL
	int "Logging interval (steps)"
	default 10
	range 1 1000
	help
	  Print training metrics every N steps.
	  Default is 10 steps.

# Performance optimizations
config GPT2_CUDNN_BENCHMARK
	bool "Enable cuDNN benchmark mode"
	default y
	depends on DEVICE = "cuda"
	help
	  Enable cuDNN autotuner for faster convolution operations.
	  Should be enabled for fixed-size inputs.

config GPT2_TF32_ALLOWED
	bool "Allow TensorFloat-32 for matmul operations"
	default y
	depends on DEVICE = "cuda"
	help
	  Allow TensorFloat-32 (TF32) for matrix multiplications.
	  Provides speedup on Ampere+ GPUs with minimal accuracy impact.

config GPT2_AMP_DTYPE
	string "Automatic Mixed Precision dtype"
	default "bfloat16"
	depends on MIXED_PRECISION
	help
	  Data type for automatic mixed precision training.

	  Options:
	    bfloat16 - Brain Float16 (recommended for AMD/NVIDIA)
	    float16  - Half precision (older GPUs)

	  bfloat16 has better numerical stability than float16.

# Generation settings
config GPT2_GENERATION_TEMPERATURE
	string "Generation temperature"
	default "0.8"
	help
	  Temperature for text generation sampling.
	  Lower values (0.5) = more focused/deterministic.
	  Higher values (1.0) = more diverse/random.

config GPT2_GENERATION_TOP_K
	int "Top-k sampling"
	default 200
	range 0 50000
	help
	  Only sample from top k tokens.
	  0 = no restriction (sample from all tokens).

config GPT2_GENERATION_MAX_TOKENS
	int "Maximum generation length"
	default 500
	range 10 10000
	help
	  Maximum number of tokens to generate.

# Advanced options
config GPT2_FLASH_ATTENTION
	bool "Use Flash Attention"
	default y
	help
	  Use Flash Attention for faster training (requires PyTorch >= 2.0).
	  Significantly reduces memory usage and increases speed.

config GPT2_COMPILE
	bool "Compile model with torch.compile()"
	default y
	depends on COMPILE_MODEL
	help
	  Use torch.compile() for faster execution.
	  Requires PyTorch >= 2.0.

config GPT2_WEIGHT_TYING
	bool "Use weight tying"
	default y
	help
	  Share weights between input embedding and output projection.
	  Standard practice for GPT models.

config GPT2_KV_TYING
	bool "Use key-value tying in attention"
	default n
	help
	  Tie key and value projections in attention (K = V).
	  Instead of creating separate linear transformations for K and V,
	  only create V and use it for both K and V.
	  This reduces parameters in attention layers by ~33%.
	  Attention computation proceeds normally after tying.

config GPT2_DROPOUT
	string "Dropout rate"
	default "0.1"
	help
	  Dropout rate for regularization.
	  0.0 = no dropout, 0.1 = 10% dropout.

config GPT2_BIAS
	bool "Use bias in Linear/LayerNorm"
	default y
	help
	  Whether to use bias terms in Linear and LayerNorm layers.
	  GPT-2 uses bias, but newer models often don't.

# Distributed Training
config GPT2_USE_DDP
	bool "Enable Distributed Data Parallel (DDP)"
	default n
	help
	  Enable multi-GPU training with PyTorch Distributed Data Parallel.
	  This allows training across multiple GPUs on one or more nodes.
	  Recommended for systems with multiple GPUs like H100x8.

config GPT2_DDP_BACKEND
	string "DDP backend"
	default "nccl"
	depends on GPT2_USE_DDP
	help
	  Backend for distributed training.
	  - nccl: NVIDIA GPUs (recommended)
	  - gloo: CPU or mixed environments
	  - mpi: MPI-based clusters

config GPT2_DDP_FIND_UNUSED_PARAMS
	bool "Find unused parameters in DDP"
	default y
	depends on GPT2_USE_DDP
	help
	  Enable finding unused parameters in the model.
	  Required for models with conditional execution paths.
	  May add slight overhead but ensures correctness.

config GPT2_DDP_NUM_GPUS
	int "Number of GPUs for DDP"
	default 1
	range 1 16
	depends on GPT2_USE_DDP
	help
	  Number of GPUs to use for distributed training.
	  This overrides PARALLEL_JOBS when DDP is enabled.
	  Set to 8 for H100x8 systems.

# AdamWPrune State Pruning Variants (Bitter Lesson)
config GPT2_ADAMWPRUNE_VARIANT_BITTER0
	bool "Enable bitter0 variant (original hybrid approach)"
	default y
	help
	  Original AdamWPrune state-based pruning using momentum-stability scoring.
	  Combines Adam momentum and stability signals for pruning decisions.
	  Result: 51.39 perplexity, 49.7% sparsity, 478.8 min training time.

config GPT2_ADAMWPRUNE_VARIANT_BITTER1
	bool "Enable bitter1 variant (pure magnitude)"
	default n
	help
	  Pure magnitude pruning with boolean masks for memory efficiency.
	  Simple approach following the bitter lesson - magnitude scoring works.
	  Expected: ~42 perplexity (similar to AdamWSPAM+magnitude), faster training.

config GPT2_ADAMWPRUNE_VARIANT_BITTER2
	bool "Enable bitter2 variant (scale-aware magnitude)"
	default n
	help
	  Magnitude pruning that signals to use saved resources:
	  - 21% more iterations (12,100 instead of 10,000)
	  - OR 14% larger batch size
	  Let scale improvements compensate for simplicity.

config GPT2_ADAMWPRUNE_VARIANT_BITTER3
	bool "Enable bitter3 variant (gradient-magnitude)"
	default n
	help
	  Gradient-magnitude pruning: |w| * sqrt(|grad_avg|)
	  Uses gradient information with cubic sparsity schedule.
	  Extended to 13000 iterations (+30%) for better quality.
	  Expected: ~42-44 perplexity, improvement over bitter2.

config GPT2_ADAMWPRUNE_VARIANT_BITTER4
	bool "Enable bitter4 variant (gradient-magnitude + layer-adaptive)"
	default n
	help
	  Gradient-magnitude with layer-adaptive sparsity distribution.
	  Early layers: 0.7x sparsity, later layers: 1.3x sparsity.
	  Extended to 13000 iterations (+30%) with cubic schedule.
	  Result: 44.88 perplexity, layer-adaptive underperformed uniform.

config GPT2_ADAMWPRUNE_VARIANT_BITTER5
	bool "Enable bitter5 variant (movement-to-zero)"
	default n
	help
	  Movement-to-zero scoring: -(sign(w) * m) / sqrt(v).
	  Identifies weights Adam is actively pushing toward zero.
	  Based on Movement Pruning but uses Adam states.
	  Expected: ~44-46 perplexity.

config GPT2_ADAMWPRUNE_VARIANT_BITTER6
	bool "Enable bitter6 variant (coherence-weighted)"
	default n
	help
	  Coherence-weighted gradient-magnitude.
	  Adds coherence signal (m^2/v) to penalize oscillatory gradients.
	  Should improve stability over bitter3.
	  Expected: ~42-44 perplexity.

config GPT2_ADAMWPRUNE_VARIANT_BITTER7
	bool "Enable bitter7 variant (second-moment based)"
	default n
	help
	  Uses second moment (exp_avg_sq) for variance-based importance.
	  High variance = uncertain = less important.
	  Low variance = stable = more important.
	  Expected: ~45-47 perplexity.

config GPT2_ADAMWPRUNE_VARIANT_BITTER8
	bool "Enable bitter8 variant (FP16 + fast rsqrt)"
	default n
	help
	  Doom-style optimization: FP16 + fast inverse sqrt.
	  Uses double rsqrt for 4th root: rsqrt(rsqrt(x)) = x^0.25
	  Benefits: 2x memory bandwidth reduction from FP16.
	  Expected: Same quality as bitter7, 30-50% faster.

config GPT2_ADAMWPRUNE_VARIANT_BITTER9
	bool "Enable bitter9 variant (bitter8 + torch.compile)"
	default n
	help
	  bitter8 with torch.compile for kernel fusion.
	  Combines FP16, fast rsqrt, and graph optimization.
	  Additional 20-40% speedup from compiled kernels.
	  Expected: Same quality as bitter7/8, maximum speed.

config GPT2_ADAMWPRUNE_DEFAULT_VARIANT
	string "Default AdamWPrune variant"
	default "bitter0"
	help
	  Default variant to use when not specified in command line.
	  Options: bitter0 (original), bitter1 (magnitude), bitter2 (scale-aware).

# Vanilla GPT-2 Ablation Studies
config GPT2_VANILLA_ABLATION_MODE
	bool "Enable vanilla GPT-2 ablation study mode"
	default n
	help
	  Run ablation study for vanilla GPT-2 architectural variants.
	  Tests different configurations like KV tying on/off.
	  When enabled, runs multiple training jobs sequentially.

config GPT2_VANILLA_ABLATION_STEPS
	string "Vanilla ablation steps to run (comma-separated)"
	default "V0,V1"
	depends on GPT2_VANILLA_ABLATION_MODE
	help
	  Comma-separated list of vanilla ablation steps to run.
	  V0: Baseline GPT-2 (no modifications)
	  V1: GPT-2 with KV tying enabled
	  Example: "V0,V1"

source "gpt2/Kconfig.mechint"

endmenu

