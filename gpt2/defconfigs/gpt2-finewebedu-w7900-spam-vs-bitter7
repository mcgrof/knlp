#
# GPT-2 FineWebEdu: AdamWSPAM vs AdamWPrune bitter7 at 50% sparsity
# Optimized for W7900 (48GB VRAM)
#
# Tests:
#   1. AdamWSPAM + magnitude pruning @ 50%
#   2. AdamWPrune bitter7 + state pruning @ 50%
#

# Model Selection - GPT-2 124M on FineWebEdu
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y

# Enable test matrix mode
CONFIG_TEST_MATRIX_MODE=y

# GPT-2 Configuration
CONFIG_GPT2_MODEL_124M=y
CONFIG_GPT2_DATASET_FINEWEBEDU=y
CONFIG_GPT2_BLOCK_SIZE=1024
CONFIG_GPT2_GRADIENT_ACCUMULATION=4

# Training settings - must set BATCH_SIZE not GPT2_BATCH_SIZE
CONFIG_BATCH_SIZE=16
CONFIG_GPT2_MAX_ITERS=50000
CONFIG_GPT2_EVAL_INTERVAL=500
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_FLASH_ATTENTION=y
# Disable torch.compile() for ROCm stability
CONFIG_GPT2_COMPILE=n
CONFIG_GPT2_WEIGHT_TYING=y
CONFIG_GPT2_DROPOUT="0.1"
CONFIG_GPT2_BIAS=y

# Optimizer Configuration - AdamWSPAM vs AdamWPrune bitter7
CONFIG_OPTIMIZER_MODE_MULTIPLE=y
CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM=y
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWPRUNE=y
# Disable other optimizers
CONFIG_OPTIMIZER_ENABLE_SGD=n
CONFIG_OPTIMIZER_ENABLE_ADAM=n
CONFIG_OPTIMIZER_ENABLE_ADAMW=n
CONFIG_OPTIMIZER_ENABLE_ADAMWADV=n

# AdamWPrune bitter7 variant
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.999"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter7"

# SPAM settings
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_WARMUP_STEPS=1000
CONFIG_SPAM_ENABLE_CLIP=y

# Pruning Configuration
CONFIG_PRUNING_MODE_MULTIPLE=y
# AdamWSPAM uses magnitude, AdamWPrune uses state
CONFIG_PRUNING_ENABLE_MAGNITUDE=y
CONFIG_PRUNING_ENABLE_STATE=y
CONFIG_PRUNING_ENABLE_MOVEMENT=n
CONFIG_PRUNING_ENABLE_NONE=n
CONFIG_TEST_PRUNING_MAGNITUDE=y
CONFIG_TEST_PRUNING_STATE=y
CONFIG_TEST_PRUNING_METHODS="magnitude,state"
CONFIG_PRUNING_WARMUP=100

# Only 50% sparsity
CONFIG_TARGET_SPARSITY="0.5"
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=n
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n
CONFIG_TEST_SPARSITY_50=y
CONFIG_TEST_SPARSITY_70=n
CONFIG_TEST_SPARSITY_90=n
CONFIG_TEST_SPARSITIES="50"

# Additional training settings (learning rate set via GPT2_MAX_ITERS above)
CONFIG_WEIGHT_DECAY="0.1"

# ROCm optimizations
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
CONFIG_TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=y

# Disable torch.compile() for ROCm stability
CONFIG_COMPILE_MODEL=n

# Tracking
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="tracking-138d5"

# Output
CONFIG_OUTPUT_DIR="./results/gpt2-spam-vs-bitter7-w7900"
