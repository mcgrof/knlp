#
# GPT-2 FineWebEdu: Test matrix comparing baseline + bitter7 + bitter8 (NO COMPILE)
#   1. Movement Pruning (baseline) - AdamWSPAM + magnitude @ 50%
#   2. bitter7 - AdamWPrune + state pruning (variance-based) @ 50%
#   3. bitter8 - AdamWPrune + state pruning (bias-corrected) @ 50%
#
# This configuration disables torch.compile() to test GPU memory usage
# and performance without compilation overhead. Useful for:
# - Memory-constrained environments
# - Comparing compile vs nocompile performance
# - Testing on GPUs with torch.compile issues
#
# Still uses CONFIG_HYPER_PARAM_AUTO for batch size auto-detection.
#

# Model Selection - GPT-2
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL="gpt2"
CONFIG_TEST_MODELS="gpt2"
CONFIG_GPT2_MODEL_SIZE="124M"

# Hyperparameter auto-detection (batch size and grad_acc)
CONFIG_HYPER_PARAM_AUTO=y
CONFIG_TARGET_EFFECTIVE_BATCH=1024

# MANUAL compile mode - explicitly disabled
CONFIG_COMPILE_MANUAL=y
CONFIG_COMPILE_MODEL=n

# Enable test matrix mode for 3-way comparison
CONFIG_TEST_MATRIX_MODE=y

# Optimizer Configuration - Test AdamWSPAM and AdamWPrune
CONFIG_OPTIMIZER_MODE_MULTIPLE=y
CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM=y
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWSPAM=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWPRUNE=y
# Disable other optimizers
CONFIG_OPTIMIZER_ENABLE_SGD=n
CONFIG_OPTIMIZER_ENABLE_ADAM=n
CONFIG_OPTIMIZER_ENABLE_ADAMW=n
CONFIG_OPTIMIZER_ENABLE_ADAMWADV=n

# SPAM settings (used by both AdamWSPAM and AdamWPrune)
CONFIG_SPAM_ENABLE_CLIP=y
CONFIG_SPAM_SPIKE_THRESHOLD="2.0"
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_WARMUP=y
CONFIG_SPAM_WARMUP_STEPS=1000
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_PERIODIC_RESET=y

# AdamWPrune specific settings
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_FREQUENCY=100
CONFIG_ADAMWPRUNE_WARMUP_STEPS=1000
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.999"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
CONFIG_ADAMWPRUNE_AMSGRAD=n

# AdamWPrune Variants - Enable bitter7 and bitter8
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER0=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER1=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER2=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER3=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER4=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER5=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER6=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER8=y
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER9=n
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter7"

# Pruning Configuration - Test magnitude and state at 50%
CONFIG_PRUNING_MODE_MULTIPLE=y
CONFIG_PRUNING_ENABLE_MAGNITUDE=y
CONFIG_PRUNING_ENABLE_MOVEMENT=n
CONFIG_PRUNING_ENABLE_STATE=y
CONFIG_PRUNING_ENABLE_NONE=n
CONFIG_PRUNING_ENABLED_MAGNITUDE=y
CONFIG_PRUNING_ENABLED_STATE=y
CONFIG_TEST_PRUNING_MAGNITUDE=y
CONFIG_TEST_PRUNING_METHODS="magnitude"

# Sparsity - Only 50% for this comparison
CONFIG_TARGET_SPARSITY="0.5"
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=n
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n
CONFIG_TEST_SPARSITY_50=y
CONFIG_TEST_SPARSITY_70=n
CONFIG_TEST_SPARSITY_90=n

# Training Parameters - Auto-detected per GPU
CONFIG_NUM_EPOCHS=10
CONFIG_GPT2_MAX_ITERS=10000
CONFIG_GPT2_EVAL_INTERVAL=500
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_LOG_INTERVAL=10

# Learning Rate Schedule
CONFIG_LEARNING_RATE="6e-4"
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y

# Dataset Configuration
CONFIG_DATA_DIR="./gpt2/data"
CONFIG_GPT2_DATASET_FINEWEBEDU=y
CONFIG_GPT2_DATASET="finewebedu"
CONFIG_GPT2_BLOCK_SIZE=1024

# Data Loading Optimization
CONFIG_NUM_WORKERS=16
CONFIG_PIN_MEMORY=y
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=4

# Mixed Precision Training
CONFIG_MIXED_PRECISION=y
CONFIG_GPT2_AMP_DTYPE="bfloat16"

# Performance Optimizations
CONFIG_GPT2_CUDNN_BENCHMARK=y
CONFIG_GPT2_TF32_ALLOWED=y
CONFIG_GPU_WARMUP=y
CONFIG_GPT2_FLASH_ATTENTION=y

# Memory Optimizations
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# Checkpointing
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_OUTPUT_DIR="./results/gpt2-baseline-bitter7-bitter8-nocompile"

# Experiment Tracking
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="gpt2-baseline-bitter7-bitter8-nocompile"
