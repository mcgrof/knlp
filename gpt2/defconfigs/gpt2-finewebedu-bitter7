#
# GPT-2 FineWebEdu: AdamWPrune bitter7 (Hardware-agnostic)
#
# Bitter7: Conservative variance-based pruning using |w| * (exp_avg_sq^0.25)
# Tests state-based pruning with optimizer momentum at 50% sparsity.
#
# FULLY OPTIMIZED IMPLEMENTATION (Nov 2025):
#
# Optimization 1 (71x threshold speedup):
# - Statistical sampling for threshold selection (2% sample)
# - 71x faster pruning (3242ms → 45ms per step)
# - 26% less memory (5440 MB → 4012 MB)
# - <0.1% accuracy loss
#
# Optimization 2 (1.8x overall + 99% memory reduction):
# - Single-pass importance computation with caching
# - Eliminates redundant Adam state reads (2x → 1x)
# - Nested sampling (1% of 100% → 5 MB vs 497 MB)
# - CPU benchmarks: 1.8x speedup, 99% concat memory reduction
#
# This configuration uses AUTO hyperparameter detection to work across
# different GPU types (B200, W7900, A10G, etc.) without modification.
#

# Model Selection - GPT-2
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y
CONFIG_MODEL="gpt2"
CONFIG_TEST_MODELS="gpt2"
CONFIG_GPT2_MODEL_SIZE="124M"

# Auto-detect torch.compile (enabled for NVIDIA, disabled for AMD W7900)
CONFIG_COMPILE_AUTO=y

# Single test mode (bitter7 only)
CONFIG_TEST_MATRIX_MODE=n

# Optimizer Configuration - AdamWPrune only
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMWPRUNE=y
CONFIG_OPTIMIZER="adamwprune"

# SPAM settings (AdamWPrune base)
CONFIG_SPAM_ENABLE_CLIP=y
CONFIG_SPAM_SPIKE_THRESHOLD="2.0"
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_WARMUP=y
CONFIG_SPAM_WARMUP_STEPS=1000
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_PERIODIC_RESET=y

# AdamWPrune specific settings
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_FREQUENCY=100
CONFIG_ADAMWPRUNE_WARMUP_STEPS=1000
CONFIG_ADAMWPRUNE_RAMP_END_STEP=3000
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.999"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
CONFIG_ADAMWPRUNE_AMSGRAD=n

# AdamWPrune Variants - ONLY bitter7
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER0=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER1=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER2=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER3=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER4=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER5=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER6=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER8=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER9=n
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter7"

# Pruning Configuration - State pruning only
CONFIG_PRUNING_MODE_SINGLE=y
CONFIG_PRUNING_SELECT_STATE=y
CONFIG_PRUNING_METHOD="state"

# Sparsity - 50% target
CONFIG_TARGET_SPARSITY="0.5"
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=n
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n

# Hyperparameter Auto-Detection (NEW!)
# Automatically selects batch size and gradient accumulation based on:
# - GPU type (B200: batch=128, W7900: batch=32, A10G: batch=8, etc.)
# - GPU memory (larger memory = larger batch)
# - GPU count (distributes effective batch across GPUs)
# - torch.compile status (compile = larger batches fit in memory)
# Target effective batch size: 1024 (maintained across all hardware)
CONFIG_HYPER_PARAM_AUTO=y
CONFIG_TARGET_EFFECTIVE_BATCH=1024

# Training Parameters - Auto-detected per GPU
# Time-based training: 2 hours for quick validation
CONFIG_NUM_EPOCHS=10
CONFIG_GPT2_MAX_TIME=7200
CONFIG_GPT2_EVAL_INTERVAL=100
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_LOG_INTERVAL=10

# Learning Rate Schedule
CONFIG_LEARNING_RATE="6e-4"
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y

# Dataset Configuration
CONFIG_DATA_DIR="./gpt2/data"
CONFIG_GPT2_DATASET_FINEWEBEDU=y
CONFIG_GPT2_DATASET="finewebedu"
CONFIG_GPT2_BLOCK_SIZE=1024

# Data Loading Optimization
CONFIG_NUM_WORKERS=16
CONFIG_PIN_MEMORY=y
CONFIG_PERSISTENT_WORKERS=y
CONFIG_PREFETCH_FACTOR=4

# Mixed Precision Training
CONFIG_MIXED_PRECISION=y
CONFIG_GPT2_AMP_DTYPE="bfloat16"

# Performance Optimizations
CONFIG_GPT2_CUDNN_BENCHMARK=y
CONFIG_GPT2_TF32_ALLOWED=y
CONFIG_GPU_WARMUP=y
CONFIG_GPT2_FLASH_ATTENTION=y

# Memory Optimizations
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# Checkpointing
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_OUTPUT_DIR="./results/gpt2-bitter7-optimized"

# Experiment Tracking
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="gpt2-bitter7-optimized"
