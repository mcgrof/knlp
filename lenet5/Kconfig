# SPDX-License-Identifier: MIT
# LeNet-5 Model Configuration

config LENET5_NUM_CLASSES
	int "Number of output classes"
	default 10
	range 2 1000
	help
	  Number of output classes for LeNet-5. Default is 10 for MNIST.

# Simplified dataset selection - only MNIST for now
config LENET5_DATASET
	string
	default "mnist"
	help
	  Dataset for LeNet-5. Currently only MNIST is supported.

config LENET5_DATASET_MNIST
	bool
	default y
	help
	  LeNet-5 trained on MNIST dataset.

menu "Image Tokenization (Experimental)"

config LENET5_ENABLE_TOKENIZER
	bool "Enable PCA-based image tokenization"
	default n
	help
	  Enable PCA-based tokenization for image inputs. Compresses
	  images into principal component space before feeding to model.

	  Benefits:
	  - Dimensionality reduction (784â†’64 for MNIST)
	  - Natural tiering hierarchy (by variance explained)
	  - Potential regularization effect

	  Requires fitting PCA on training data before use.

choice
	prompt "Tokenizer type"
	default LENET5_TOKENIZER_PCA
	depends on LENET5_ENABLE_TOKENIZER
	help
	  Choose tokenization strategy.

config LENET5_TOKENIZER_PCA
	bool "PCA tokenizer"
	help
	  Simple PCA-based tokenization. Projects images into
	  principal component space and tiers by variance explained.

	  Fast, simple, effective for MNIST.

config LENET5_TOKENIZER_SPLINE_PCA
	bool "Spline-PCA tokenizer"
	help
	  Advanced tokenization with spline trajectory compression.
	  Tracks how PCA components evolve during training and fits
	  cubic splines to trajectories.

	  Enables:
	  - Temporal tiering (by component update frequency)
	  - Trajectory compression (splines vs full history)
	  - Online learning (update control points)

	  Slower but more sophisticated than basic PCA.

endchoice

config LENET5_TOKENIZER_METHOD
	string
	default "none" if !LENET5_ENABLE_TOKENIZER
	default "pca" if LENET5_TOKENIZER_PCA
	default "spline-pca" if LENET5_TOKENIZER_SPLINE_PCA

config LENET5_PCA_COMPONENTS
	int "Number of PCA components"
	default 64
	range 8 784
	depends on LENET5_ENABLE_TOKENIZER
	help
	  Number of principal components to keep. For MNIST (784 dims):
	  - 32 components: ~90% variance, 24x compression
	  - 64 components: ~95% variance, 12x compression
	  - 128 components: ~98% variance, 6x compression

	  Lower values = more compression but potential quality loss.
	  Higher values = less compression but better quality.

config LENET5_PCA_WHITEN
	bool "Enable PCA whitening"
	default n
	depends on LENET5_ENABLE_TOKENIZER
	help
	  Normalize PCA components by their variance. Makes all
	  components have unit variance, which can help with
	  optimization but removes natural importance hierarchy.

	  Usually not needed for tiering (we want variance hierarchy).

config LENET5_SPLINE_CONTROL_POINTS
	int "Number of spline control points"
	default 8
	range 4 32
	depends on LENET5_TOKENIZER_SPLINE_PCA
	help
	  Number of control points for cubic spline fitting of
	  component trajectories. More points = better fit but
	  less compression.

	  For 10-epoch training:
	  - 4 points: High compression, smooth approximation
	  - 8 points: Balanced (recommended)
	  - 16 points: Low compression, detailed trajectory

config LENET5_TOKENIZER_SAVE_PATH
	string "Tokenizer save path"
	default "lenet5_tokenizer.pkl"
	depends on LENET5_ENABLE_TOKENIZER
	help
	  Path to save fitted tokenizer for later use.

endmenu

menu "AdamWPrune Variants (Bitter)"

config LENET5_ADAMWPRUNE_VARIANT_BITTER0
	bool "Enable bitter0 variant (original hybrid)"
	default y
	help
	  Original hybrid approach combining momentum magnitude
	  with stability criterion. Formula:
	  |w| * |exp_avg| * |w| / sqrt(exp_avg_sq)

config LENET5_ADAMWPRUNE_VARIANT_BITTER7
	bool "Enable bitter7 variant (variance-based)"
	default n
	help
	  Conservative variance-based pruning using second moment.
	  Formula: |w| * (exp_avg_sq^0.25)

	  Beta2=0.999 tracks ~1000 steps of variance accumulation,
	  providing better signal than momentum-based methods.

	  Achieves 15.6% better perplexity than magnitude baseline
	  on GPT-2 transformers (37.28 vs 44.15 PPL).

config LENET5_ADAMWPRUNE_VARIANT_BITTER8
	bool "Enable bitter8 variant (bias-corrected + fast rsqrt)"
	default n
	help
	  Bias-corrected gradient-magnitude with GPU optimization.
	  Formula: |w| * sqrt(|m_hat|) where m_hat uses bias correction

	  Uses FP16 precision and fast inverse sqrt (rsqrt) for
	  30-50% faster pruning with 2x less memory bandwidth.

config LENET5_ADAMWPRUNE_DEFAULT_VARIANT
	string "Default AdamWPrune variant"
	default "bitter0" if LENET5_ADAMWPRUNE_VARIANT_BITTER0
	default "bitter7" if LENET5_ADAMWPRUNE_VARIANT_BITTER7
	default "bitter8" if LENET5_ADAMWPRUNE_VARIANT_BITTER8
	help
	  Default variant to use when AdamWPrune optimizer is selected.
	  bitter0: Original hybrid (works well on CNNs)
	  bitter7: Variance-based (best for transformers, expected to improve CNNs)
	  bitter8: Optimized bitter7 with FP16 and fast rsqrt

endmenu
