# LeNet-5 Test Matrix: Magnitude vs State-Based (bitter0) vs bitter7
# Run with: make defconfig-lenet5-baseline-vs-bitter7 && make
#
# Runs 3 tests:
#   1. AdamW + magnitude pruning @ 70% (baseline)
#   2. AdamWPrune + state pruning (bitter0) @ 70% (original algorithm)
#   3. AdamWPrune + state pruning (bitter7) @ 70% (variance-based)
#
# All tests use identical hyperparameters for fair "compute budget" comparison:
# - Time-based training: 240s (4 minutes)
# - 70% sparsity
# - batch_size=512
# - lr=0.001
# - Graphs use step count for apples-to-apples comparison
#
# Expected results:
# - Magnitude baseline: ~95-96% accuracy
# - bitter0: ~98.9% accuracy (from previous experiments)
# - bitter7: >= 98.9% accuracy (expected improvement)

# Model configuration
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_LENET5=y
CONFIG_LENET5_DATASET_MNIST=y
CONFIG_LENET5_NUM_CLASSES=10

# Enable test matrix mode for 3-way comparison
CONFIG_TEST_MATRIX_MODE=y

# Optimizers: AdamW and AdamWPrune
CONFIG_OPTIMIZER_MODE_MULTIPLE=y
CONFIG_OPTIMIZER_ENABLE_ADAMW=y
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMW=y
CONFIG_TEST_OPTIMIZER_ENABLED_ADAMWPRUNE=y
# Disable other optimizers
CONFIG_OPTIMIZER_ENABLE_SGD=n
CONFIG_OPTIMIZER_ENABLE_ADAM=n
CONFIG_OPTIMIZER_ENABLE_ADAMWADV=n
CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM=n

# AdamW settings (for baseline)
CONFIG_ADAMW_WEIGHT_DECAY="0.01"
CONFIG_ADAMW_BETA1="0.9"
CONFIG_ADAMW_BETA2="0.999"

# AdamWPrune settings
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.999"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.01"
CONFIG_ADAMWPRUNE_AMSGRAD=n
CONFIG_ADAMWPRUNE_WARMUP_STEPS=100
CONFIG_ADAMWPRUNE_FREQUENCY=50

# bitter variants: Enable bitter0 and bitter7
CONFIG_LENET5_ADAMWPRUNE_VARIANT_BITTER0=y
CONFIG_LENET5_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_LENET5_ADAMWPRUNE_VARIANT_BITTER8=n
CONFIG_LENET5_ADAMWPRUNE_DEFAULT_VARIANT="bitter0"

# Pruning: Test magnitude and state at 70%
CONFIG_PRUNING_MODE_MULTIPLE=y
CONFIG_PRUNING_ENABLE_MAGNITUDE=y
CONFIG_PRUNING_ENABLE_STATE=y
CONFIG_PRUNING_ENABLED_MAGNITUDE=y
CONFIG_PRUNING_ENABLED_STATE=y
CONFIG_TEST_PRUNING_MAGNITUDE=y
CONFIG_TEST_PRUNING_METHODS="magnitude"

# Sparsity: Only 70% for this comparison
CONFIG_TARGET_SPARSITY="0.7"
CONFIG_SPARSITY_ENABLE_50=n
CONFIG_SPARSITY_ENABLE_70=y
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n
CONFIG_TEST_SPARSITY_70=y

# Training configuration
CONFIG_BATCH_SIZE=512
CONFIG_LEARNING_RATE="0.001"
CONFIG_NUM_WORKERS=16

# Time-based training: 240s (4 minutes)
# Set epochs high so time limit stops training, not epoch count
CONFIG_NUM_EPOCHS=100
CONFIG_LENET5_MAX_TIME=240

# Performance features
CONFIG_MIXED_PRECISION=y
CONFIG_PIN_MEMORY=y
CONFIG_PERSISTENT_WORKERS=y

# Tracking (W&B and Trackio)
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="lenet5-baseline-vs-bitter7"

# Logging
CONFIG_SAVE_CHECKPOINT=y
CONFIG_PRUNING_LOG_SPARSITY=y
CONFIG_VERBOSE=y
