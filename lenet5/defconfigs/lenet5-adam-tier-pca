# LeNet-5 with PCA Tokenization + Tiering (Phase 2.2)
# Run with: make defconfig-lenet5-adam-tier-pca && make DEVICE=cpu
#
# Tests PCA-based image tokenization combined with hierarchical
# memory tiering. This is Phase 2.2 of the spline-PCA roadmap.
#
# What this does:
# - Compresses MNIST images: 784 dims → 64 PCA components (12x)
# - Tiers components by variance explained (spatial hierarchy)
# - High-variance components (digit shape) → hot tier
# - Low-variance components (noise/style) → cold tier
#
# Purpose: Validate that PCA compression works and creates natural
# tiering hierarchy. Expected ~99% accuracy (within 1% of baseline)
# with 12x input dimensionality reduction.
#
# After training, generates tier_hints_lenet5_pca.json showing which
# PCA components are hot vs cold, and saves fitted tokenizer to
# lenet5_tokenizer_pca.pkl for reuse.
#
# Expected results:
# - Accuracy: ~99.0-99.2% (compression may act as regularization)
# - Training time: ~50 min (similar to baseline)
# - Top 16 components: Capture ~80% variance (digit shape) - HOT
# - Next 32 components: Capture ~15% variance (details) - WARM
# - Last 16 components: Capture ~5% variance (noise) - COLD

# Enable LeNet-5 model
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_LENET5=y
CONFIG_MODEL_LENET5=y
CONFIG_MODEL="lenet5"
CONFIG_LENET5_DATASET_MNIST=y

# Use AdamW optimizer (needed for Adam state analysis)
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMW=y
CONFIG_OPTIMIZER="adamw"
CONFIG_ADAMW_BETA1="0.9"
CONFIG_ADAMW_BETA2="0.999"
CONFIG_ADAMW_EPSILON="1e-8"
CONFIG_ADAMW_WEIGHT_DECAY="0.0001"

# No pruning for baseline
CONFIG_PRUNING_MODE_NONE=y
CONFIG_PRUNING_METHOD="none"

# Hyperparameter auto-detection (see docs/hyperparameter-auto-detection.md)
# Auto-detects CPU and selects appropriate batch size
# LeNet-5 uses 4x scale factor for larger batches when memory permits
CONFIG_HYPER_PARAM_AUTO=y
CONFIG_TARGET_EFFECTIVE_BATCH=512
CONFIG_COMPILE_AUTO=y

# Training configuration - CPU optimized
CONFIG_NUM_EPOCHS=10
CONFIG_LEARNING_RATE="0.001"
CONFIG_NUM_WORKERS=4
CONFIG_DEVICE="cpu"

# Disable GPU-specific features for CPU training
CONFIG_COMPILE_MODEL=n
CONFIG_MIXED_PRECISION=n
CONFIG_GPU_WARMUP=n
CONFIG_PIN_MEMORY=n
CONFIG_PERSISTENT_WORKERS=y

# PCA Tokenization (Phase 2.2)
CONFIG_LENET5_ENABLE_TOKENIZER=y
CONFIG_LENET5_TOKENIZER_PCA=y
CONFIG_LENET5_TOKENIZER_METHOD="pca"
CONFIG_LENET5_PCA_COMPONENTS=64
CONFIG_LENET5_PCA_WHITEN=n
CONFIG_LENET5_TOKENIZER_SAVE_PATH="lenet5_tokenizer_pca.pkl"

# Hierarchical Memory Tiering - Emulated Mode
CONFIG_ENABLE_HIERARCHICAL_TIERING=y
CONFIG_TIERING_ADAM_STATE=y
CONFIG_TIERING_EMULATED=y
CONFIG_TIERING_GENERATE_JSON=y
CONFIG_TIERING_JSON_OUTPUT="tier_hints_lenet5_pca.json"
# Conservative thresholds: 30% hot (L1/L2), 50% warm (RAM), 20% cold (SSD)
CONFIG_TIERING_HBM_THRESHOLD="0.3"
CONFIG_TIERING_CPU_THRESHOLD="0.5"
CONFIG_TIERING_INFERENCE_BENCHMARK=n

# Experiment Tracking (W&B and Trackio)
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="lenet5-tiering"

# Logging
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_VERBOSE=y

# Test execution (single training run)
CONFIG_TEST_MATRIX_MODE=n
CONFIG_OUTPUT_DIR="lenet5_tier_pca"
