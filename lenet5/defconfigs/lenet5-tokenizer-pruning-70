# LeNet-5 Tokenizer × Pruning Methods @ 70% Sparsity
# Run with: make defconfig-lenet5-tokenizer-pruning-70 && make
#
# Tests tokenization methods combined with pruning:
#   Tokenizers: baseline, PCA, Spline-PCA (3 variants)
#   Pruning: state (bitter7), movement (2 methods)
#   Total: 3 × 2 = 6 test combinations
#
# All tests use equal compute budget (104s) and 70% target sparsity.
#
# Research questions:
# 1. Does PCA compression interact well with pruning? (smaller model, easier to prune?)
# 2. Which pruning method works better with dimensionality reduction?
# 3. Can we combine 12x input compression + 70% weight sparsity?
#
# Expected parameter reductions:
# - Baseline + 70% pruning: 70% weight reduction
# - PCA + 70% pruning: 12x input reduction + 70% FC weight reduction
# - Spline-PCA + 70% pruning: 12x input + trajectory compression + 70% weights

# Enable LeNet-5 model
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_LENET5=y
CONFIG_MODEL_LENET5=y
CONFIG_MODEL="lenet5"
CONFIG_LENET5_DATASET_MNIST=y

# Test matrix mode
CONFIG_TEST_MATRIX_MODE=y
CONFIG_OUTPUT_DIR="test_matrix_results_lenet5_tokenizer_pruning_70"

# Tokenizer methods (3 variants)
CONFIG_LENET5_ENABLE_TOKENIZER=y
CONFIG_LENET5_PCA_COMPONENTS=64
CONFIG_LENET5_PCA_WHITEN=n
CONFIG_LENET5_SPLINE_CONTROL_POINTS=8
CONFIG_LENET5_TOKENIZER_SAVE_PATH="lenet5_tokenizer.pkl"

CONFIG_TEST_TOKENIZER_BASELINE=y
CONFIG_TEST_TOKENIZER_PCA=y
CONFIG_TEST_TOKENIZER_SPLINE_PCA=y
CONFIG_TEST_TOKENIZER_METHODS="none,pca,spline-pca"

# Pruning methods (2 variants: state with bitter7, movement)
# Use PRUNING_MODE_MULTIPLE and selectively enable methods
CONFIG_PRUNING_MODE_MULTIPLE=y
# CONFIG_PRUNING_ENABLE_NONE is not set
# CONFIG_PRUNING_ENABLE_MAGNITUDE is not set
CONFIG_PRUNING_ENABLE_MOVEMENT=y
CONFIG_PRUNING_ENABLE_STATE=y

# Sparsity levels - only test 70%
# CONFIG_SPARSITY_ENABLE_50 is not set
CONFIG_SPARSITY_ENABLE_70=y
# CONFIG_SPARSITY_ENABLE_90 is not set
# CONFIG_SPARSITY_ENABLE_95 is not set
# CONFIG_SPARSITY_ENABLE_99 is not set

# Pruning configuration
CONFIG_TARGET_SPARSITY="0.7"
CONFIG_PRUNING_WARMUP=100
CONFIG_PRUNING_FREQUENCY=50
CONFIG_PRUNING_RAMP_END_EPOCH=8

# State-based pruning: bitter7 variant only (variance-based tiering)
# CONFIG_LENET5_ADAMWPRUNE_VARIANT_BITTER0 is not set
CONFIG_LENET5_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_LENET5_ADAMWPRUNE_DEFAULT_VARIANT="bitter7"
CONFIG_STATE_PRUNING_STRATEGY="hybrid"
CONFIG_STATE_PRUNING_MOMENTUM_WEIGHT="0.5"

# Movement pruning settings
CONFIG_MOVEMENT_PRUNING_BETA="0.9"
CONFIG_MOVEMENT_PRUNING_USE_GRADIENT=y

# Optimizers: AdamW for movement pruning, AdamWPrune for state pruning (bitter7)
CONFIG_OPTIMIZER_MODE_MULTIPLE=y
# CONFIG_OPTIMIZER_ENABLE_SGD is not set
# CONFIG_OPTIMIZER_ENABLE_ADAM is not set
CONFIG_OPTIMIZER_ENABLE_ADAMW=y
# CONFIG_OPTIMIZER_ENABLE_ADAMWADV is not set
# CONFIG_OPTIMIZER_ENABLE_ADAMWSPAM is not set
CONFIG_OPTIMIZER_ENABLE_ADAMWPRUNE=y
CONFIG_ADAMW_BETA1="0.9"
CONFIG_ADAMW_BETA2="0.999"
CONFIG_ADAMW_EPSILON="1e-8"
CONFIG_ADAMW_WEIGHT_DECAY="0.0001"
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y

# Hyperparameter auto-detection
CONFIG_HYPER_PARAM_AUTO=y
CONFIG_TARGET_EFFECTIVE_BATCH=512
CONFIG_COMPILE_AUTO=y

# Training configuration - equal time budget
CONFIG_NUM_EPOCHS=100
CONFIG_LENET5_MAX_TIME=104
CONFIG_LEARNING_RATE="0.001"
CONFIG_NUM_WORKERS=4
CONFIG_DEVICE="cpu"

# Disable GPU-specific features for CPU training
CONFIG_COMPILE_MODEL=n
CONFIG_MIXED_PRECISION=n
CONFIG_GPU_WARMUP=n
CONFIG_PIN_MEMORY=n
CONFIG_PERSISTENT_WORKERS=y

# Hierarchical Memory Tiering - Emulated Mode
CONFIG_ENABLE_HIERARCHICAL_TIERING=y
CONFIG_TIERING_ADAM_STATE=y
CONFIG_TIERING_EMULATED=y
CONFIG_TIERING_GENERATE_JSON=y
CONFIG_TIERING_JSON_OUTPUT="tier_hints_lenet5_pruning.json"
CONFIG_TIERING_HBM_THRESHOLD="0.3"
CONFIG_TIERING_CPU_THRESHOLD="0.5"
CONFIG_TIERING_INFERENCE_BENCHMARK=n

# Experiment Tracking (W&B and Trackio)
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="lenet5-tokenizer-pruning-70"

# Logging
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_VERBOSE=y
