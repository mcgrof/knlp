# LeNet-5 Tokenizer Comparison: Baseline vs PCA vs Spline-PCA
# Run with: make defconfig-lenet5-tokenizer-comparison && lenet5/run_tokenizer_comparison.sh
#
# Runs 3 experiments to compare tokenization approaches:
#   1. Baseline: No tokenization (reference, 784 dims input)
#   2. PCA: Spatial tiering by variance (784â†’64 dims, 12x compression)
#   3. Spline-PCA: Spatial + temporal tiering (trajectories + variance)
#
# This is the complete spline-PCA roadmap validation on LeNet-5/MNIST:
# - Baseline: Establishes reference (~99.2% accuracy, 784 input dims)
# - PCA (Phase 2.2): Validates dimensionality reduction + spatial tiering
# - Spline-PCA (Phase 2.3): Adds temporal tiering via trajectory tracking
#
# Expected results:
# - Baseline: ~99.2% accuracy, 784 input dims, ~50 min
# - PCA: ~99.0-99.2% accuracy, 64 input dims (12x compression), ~50 min
# - Spline-PCA: ~99.0-99.2% accuracy, 64 dims + trajectories, ~55 min
#
# All results go to W&B project "lenet5-tokenizer-comparison" for comparison.

# Enable LeNet-5 model
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_LENET5=y
CONFIG_MODEL_LENET5=y
CONFIG_MODEL="lenet5"
CONFIG_LENET5_DATASET_MNIST=y

# Use AdamW optimizer
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMW=y
CONFIG_OPTIMIZER="adamw"
CONFIG_ADAMW_BETA1="0.9"
CONFIG_ADAMW_BETA2="0.999"
CONFIG_ADAMW_EPSILON="1e-8"
CONFIG_ADAMW_WEIGHT_DECAY="0.0001"

# No pruning
CONFIG_PRUNING_MODE_NONE=y
CONFIG_PRUNING_METHOD="none"

# Hyperparameter auto-detection (see docs/hyperparameter-auto-detection.md)
# Auto-detects CPU and selects appropriate batch size
# LeNet-5 uses 4x scale factor for larger batches when memory permits
CONFIG_HYPER_PARAM_AUTO=y
CONFIG_TARGET_EFFECTIVE_BATCH=512
CONFIG_COMPILE_AUTO=y

# Training configuration - CPU optimized
CONFIG_NUM_EPOCHS=10
CONFIG_LEARNING_RATE="0.001"
CONFIG_NUM_WORKERS=4
CONFIG_DEVICE="cpu"

# Disable GPU-specific features for CPU training
CONFIG_COMPILE_MODEL=n
CONFIG_MIXED_PRECISION=n
CONFIG_GPU_WARMUP=n
CONFIG_PIN_MEMORY=n
CONFIG_PERSISTENT_WORKERS=y

# Tokenization settings
CONFIG_LENET5_ENABLE_TOKENIZER=y
CONFIG_LENET5_PCA_COMPONENTS=64
CONFIG_LENET5_PCA_WHITEN=n
CONFIG_LENET5_SPLINE_CONTROL_POINTS=8
CONFIG_LENET5_TOKENIZER_SAVE_PATH="lenet5_tokenizer.pkl"

# Test matrix: baseline, pca, spline-pca
CONFIG_TEST_TOKENIZER_BASELINE=y
CONFIG_TEST_TOKENIZER_PCA=y
CONFIG_TEST_TOKENIZER_SPLINE_PCA=y
CONFIG_TEST_TOKENIZER_METHODS="none,pca,spline-pca"

# Hierarchical Memory Tiering - Emulated Mode
CONFIG_ENABLE_HIERARCHICAL_TIERING=y
CONFIG_TIERING_ADAM_STATE=y
CONFIG_TIERING_EMULATED=y
CONFIG_TIERING_GENERATE_JSON=y
CONFIG_TIERING_JSON_OUTPUT="tier_hints_lenet5.json"
# Conservative thresholds: 30% hot (L1/L2), 50% warm (RAM), 20% cold (SSD)
CONFIG_TIERING_HBM_THRESHOLD="0.3"
CONFIG_TIERING_CPU_THRESHOLD="0.5"
CONFIG_TIERING_INFERENCE_BENCHMARK=n

# Experiment Tracking (W&B and Trackio)
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="lenet5-tokenizer-comparison"

# Logging
CONFIG_SAVE_CHECKPOINT=y
CONFIG_CHECKPOINT_INTERVAL=1000
CONFIG_VERBOSE=y

# Test matrix mode - runs all 3 tokenizer variations
CONFIG_TEST_MATRIX_MODE=y
CONFIG_OUTPUT_DIR="test_matrix_results_lenet5_tokenizer"
