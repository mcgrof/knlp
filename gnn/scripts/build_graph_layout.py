#!/usr/bin/env python3
"""
Build graph-based node layout for reduced read amplification.

Uses the actual graph structure (edge_index) to group connected nodes
into pages. This ensures neighbors sampled together during GNN training
are likely on the same page, reducing read amplification.

Two methods are available:
  - bfs: Simple BFS from high-degree seeds (43% improvement)
  - metis: Hierarchical Metis partitioning + BFS (55% improvement)

Usage:
    python scripts/build_graph_layout.py --data-dir ./data --output layout.npz
    python scripts/build_graph_layout.py --dataset ogbn-products --method metis --output layout_ogbn_products.npz
"""

import argparse
import json
import os
import sys
import time
from collections import defaultdict
from datetime import datetime

import numpy as np
import torch

# Import dataset loaders from datasets.py
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from datasets import (
    load_dgraphfin,
    load_yelpchi,
    load_amazon,
    load_elliptic,
    load_ogbn_products,
    load_ogbn_proteins,
)


def load_ieee_cis(root="./data"):
    """Load IEEE-CIS fraud detection dataset from npz file."""
    import os

    npz_path = os.path.join(root, "ieee-cis.npz")
    data = np.load(npz_path)

    x = torch.from_numpy(data["x"]).float()
    y = torch.from_numpy(data["y"]).long()
    # IEEE-CIS edge_index is already [2, E]
    edge_index = torch.from_numpy(data["edge_index"]).long()
    train_mask = torch.from_numpy(data["train_mask"])

    # Return as simple namespace-like object
    class Data:
        pass

    result = Data()
    result.x = x
    result.y = y
    result.edge_index = edge_index
    result.train_mask = train_mask
    return result


def load_dcsbm(dcsbm_dir: str, num_features: int = 17):
    """
    Load a DC-SBM synthetic graph generated by generate_dcsbm_graph.py.

    Args:
        dcsbm_dir: Directory containing edges.npy, blocks.npy, meta.json
        num_features: Number of synthetic features per node (default: 17 like DGraphFin)

    Returns:
        Data object with x, y, edge_index attributes
    """
    import json

    edges_path = os.path.join(dcsbm_dir, "edges.npy")
    blocks_path = os.path.join(dcsbm_dir, "blocks.npy")
    meta_path = os.path.join(dcsbm_dir, "meta.json")

    if not os.path.exists(edges_path):
        raise FileNotFoundError(f"Edges file not found: {edges_path}")

    # Load edges
    edges = np.load(edges_path)
    num_edges = len(edges)

    # Load metadata for num_nodes
    with open(meta_path, "r") as f:
        meta = json.load(f)
    num_nodes = meta["num_nodes"]

    print(f"Loading DC-SBM synthetic graph:")
    print(f"  Nodes: {num_nodes:,}")
    print(f"  Edges: {num_edges:,}")
    print(f"  Avg degree: {meta['avg_degree']:.2f}")
    print(f"  Intra-block edges: {100*meta['intra_block_fraction']:.1f}%")

    # Convert to PyTorch edge_index [2, E]
    edge_index = torch.from_numpy(edges.T).long()

    # Create synthetic features (random for layout building - features don't affect layout)
    x = torch.randn(num_nodes, num_features)

    # Use block membership as labels
    blocks = np.load(blocks_path)
    y = torch.from_numpy(blocks).long()

    # Create simple Data object
    class Data:
        pass

    result = Data()
    result.x = x
    result.y = y
    result.edge_index = edge_index
    result.train_mask = torch.ones(num_nodes, dtype=torch.bool)
    result.meta = meta

    return result


def build_bfs_layout(edge_index, num_nodes, nodes_per_page=60):
    """
    Build page-aware node ordering using BFS on graph structure.

    Args:
        edge_index: Graph edges [2, E]
        num_nodes: Total number of nodes
        nodes_per_page: Target nodes per page

    Returns:
        node_order: Tensor mapping new_id -> original_id
        page_id: Array mapping original_id -> page index
        summary: Dict of layout quality stats
    """
    print(f"Building graph-based layout for {num_nodes:,} nodes...")

    # Build adjacency list (incoming edges for neighbor sampling)
    t0 = time.time()
    adj = defaultdict(list)
    src, dst = edge_index[0].numpy(), edge_index[1].numpy()
    for i in range(len(src)):
        adj[dst[i]].append(src[i])
    print(f"  Adjacency list built in {time.time()-t0:.1f}s")

    # Compute degrees
    degrees = np.array([len(adj[i]) for i in range(num_nodes)])
    print(
        f"  Degree: min={degrees.min()}, max={degrees.max()}, mean={degrees.mean():.1f}"
    )
    print(f"  Isolated nodes: {(degrees == 0).sum():,}")

    # Page-aware BFS layout
    t0 = time.time()
    visited = np.zeros(num_nodes, dtype=bool)
    node_order = []
    pages = []

    # Sort seeds by degree (high-degree nodes are more likely to be sampled)
    seed_order = np.argsort(-degrees)

    for seed in seed_order:
        if visited[seed]:
            continue

        # Start a new page with BFS from this seed
        page_nodes = []
        queue = [seed]

        while queue and len(page_nodes) < nodes_per_page:
            node = queue.pop(0)
            if visited[node]:
                continue
            visited[node] = True
            page_nodes.append(node)

            # Add neighbors to queue (using actual graph structure)
            for neighbor in adj[node]:
                if not visited[neighbor]:
                    queue.append(neighbor)

        if page_nodes:
            pages.append(page_nodes)
            node_order.extend(page_nodes)

    # Handle remaining isolated/unreached nodes
    remaining = np.where(~visited)[0]
    for start in range(0, len(remaining), nodes_per_page):
        chunk = remaining[start : start + nodes_per_page].tolist()
        pages.append(chunk)
        node_order.extend(chunk)

    print(f"  Layout built in {time.time()-t0:.1f}s")

    # Convert to arrays
    node_order = torch.tensor(node_order, dtype=torch.long)
    page_id = np.zeros(num_nodes, dtype=np.int64)
    for pid, pg in enumerate(pages):
        for nid in pg:
            page_id[nid] = pid

    # Calculate intra-page edge fraction
    same_page = page_id[src] == page_id[dst]
    intra_edges = same_page.sum()
    num_edges = len(src)

    page_sizes = [len(pg) for pg in pages]
    summary = {
        "method": "graph_bfs",
        "num_nodes": num_nodes,
        "num_edges": num_edges,
        "nodes_per_page_target": nodes_per_page,
        "num_pages": len(pages),
        "avg_page_size": float(np.mean(page_sizes)),
        "max_page_size": int(np.max(page_sizes)),
        "full_pages": sum(1 for s in page_sizes if s == nodes_per_page),
        "intra_page_edges": int(intra_edges),
        "intra_edge_fraction": float(intra_edges / num_edges),
        "created": datetime.now().isoformat(),
    }

    return node_order, page_id, summary


def build_metis_layout(edge_index, num_nodes, nodes_per_page=60, num_partitions=1000):
    """
    Build page layout using hierarchical Metis partitioning + BFS.

    First uses Metis to create coarse balanced partitions that minimize
    edge cuts. Then within each partition, uses BFS to create pages.
    This achieves better locality than simple BFS alone.

    Args:
        edge_index: Graph edges [2, E]
        num_nodes: Total number of nodes
        nodes_per_page: Target nodes per page
        num_partitions: Number of coarse Metis partitions

    Returns:
        node_order: Tensor mapping new_id -> original_id
        page_id: Array mapping original_id -> page index
        summary: Dict of layout quality stats
    """
    try:
        import pymetis
    except ImportError:
        raise ImportError(
            "pymetis not installed. Install with: pip install pymetis\n"
            "Or use --method bfs instead."
        )

    print(f"Building Metis+BFS layout for {num_nodes:,} nodes...")
    src, dst = edge_index[0].numpy(), edge_index[1].numpy()
    num_edges = len(src)

    # Build undirected adjacency for Metis
    t0 = time.time()
    adj = defaultdict(set)
    for i in range(num_edges):
        adj[src[i]].add(dst[i])
        adj[dst[i]].add(src[i])
    adjacency = [list(adj[i]) for i in range(num_nodes)]
    print(f"  Adjacency built in {time.time()-t0:.1f}s")

    # Run Metis partitioning
    print(f"  Running Metis ({num_partitions} partitions)...")
    t0 = time.time()
    cuts, membership = pymetis.part_graph(num_partitions, adjacency=adjacency)
    print(f"  Metis done in {time.time()-t0:.1f}s, edge cuts: {cuts:,}")

    # Group nodes by partition
    partition_nodes = defaultdict(list)
    for node_id, part_id in enumerate(membership):
        partition_nodes[part_id].append(node_id)

    # Build pages with BFS within each partition
    print("  Building pages with BFS within partitions...")
    t0 = time.time()
    node_order = []
    page_id = np.zeros(num_nodes, dtype=np.int64)
    current_page = 0

    for part_id in range(num_partitions):
        part_nodes = partition_nodes[part_id]
        if not part_nodes:
            continue

        # Build local adjacency within this partition
        part_set = set(part_nodes)
        local_adj = {n: [nb for nb in adj[n] if nb in part_set] for n in part_nodes}

        # BFS within partition
        visited = set()
        part_nodes_sorted = sorted(part_nodes, key=lambda n: -len(local_adj[n]))

        for seed in part_nodes_sorted:
            if seed in visited:
                continue

            page_nodes = []
            queue = [seed]

            while queue and len(page_nodes) < nodes_per_page:
                node = queue.pop(0)
                if node in visited:
                    continue
                visited.add(node)
                page_nodes.append(node)

                for neighbor in local_adj[node]:
                    if neighbor not in visited:
                        queue.append(neighbor)

            if page_nodes:
                node_order.extend(page_nodes)
                for n in page_nodes:
                    page_id[n] = current_page
                current_page += 1

    print(f"  Pages built in {time.time()-t0:.1f}s")

    # Convert to tensor
    node_order = torch.tensor(node_order, dtype=torch.long)

    # Calculate intra-page edge fraction
    same_page = page_id[src] == page_id[dst]
    intra_edges = same_page.sum()

    summary = {
        "method": "metis_bfs",
        "num_nodes": num_nodes,
        "num_edges": num_edges,
        "nodes_per_page_target": nodes_per_page,
        "metis_partitions": num_partitions,
        "metis_cuts": int(cuts),
        "num_pages": current_page,
        "intra_page_edges": int(intra_edges),
        "intra_edge_fraction": float(intra_edges / num_edges),
        "created": datetime.now().isoformat(),
    }

    return node_order, page_id, summary


def main():
    parser = argparse.ArgumentParser(description="Build graph-based layout")
    parser.add_argument(
        "--dataset",
        type=str,
        default="dgraphfin",
        choices=[
            "dgraphfin",
            "yelpchi",
            "amazon",
            "elliptic",
            "ogbn-products",
            "ogbn-proteins",
            "ieee-cis",
            "dcsbm",
        ],
        help="Dataset to build layout for",
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        default="./data",
        help="Directory containing dataset data",
    )
    parser.add_argument(
        "--dcsbm-dir",
        type=str,
        default=None,
        help="Directory containing DC-SBM generated graph (required when --dataset dcsbm)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Output layout file (default: layout_{dataset}.npz)",
    )
    parser.add_argument(
        "--method",
        type=str,
        choices=["bfs", "metis"],
        default="metis",
        help="Layout method: bfs (43%% improvement) or metis (55%% improvement)",
    )
    parser.add_argument(
        "--metis-partitions",
        type=int,
        default=1000,
        help="Number of coarse Metis partitions (for --method metis)",
    )
    parser.add_argument(
        "--page-size",
        type=int,
        default=4096,
        help="Page size in bytes",
    )
    parser.add_argument(
        "--bytes-per-node",
        type=int,
        default=None,
        help="Bytes per node feature (auto-detected from dataset if not specified)",
    )
    args = parser.parse_args()

    # Set default output filename based on dataset
    if args.output is None:
        args.output = f"layout_{args.dataset.replace('-', '_')}.npz"

    # Load dataset
    print(f"Loading {args.dataset} dataset...")
    if args.dataset == "dgraphfin":
        data = load_dgraphfin(root=args.data_dir)
    elif args.dataset == "yelpchi":
        data = load_yelpchi(root=args.data_dir)
    elif args.dataset == "amazon":
        data = load_amazon(root=args.data_dir)
    elif args.dataset == "elliptic":
        data = load_elliptic(root=args.data_dir)
    elif args.dataset == "ogbn-products":
        data = load_ogbn_products(root=args.data_dir)
    elif args.dataset == "ogbn-proteins":
        data = load_ogbn_proteins(root=args.data_dir)
    elif args.dataset == "ieee-cis":
        data = load_ieee_cis(root=args.data_dir)
    elif args.dataset == "dcsbm":
        if args.dcsbm_dir is None:
            parser.error("--dcsbm-dir is required when using --dataset dcsbm")
        data = load_dcsbm(dcsbm_dir=args.dcsbm_dir)

    edge_index = data.edge_index
    x = data.x
    num_nodes = x.size(0)
    num_features = x.size(1)

    # Auto-detect bytes per node if not specified
    if args.bytes_per_node is None:
        args.bytes_per_node = num_features * 4  # float32

    print(f"  Nodes: {num_nodes:,}")
    print(f"  Edges: {edge_index.size(1):,}")
    print(f"  Features: {num_features}")
    print(f"  Bytes per node: {args.bytes_per_node}")

    # Calculate nodes per page
    nodes_per_page = args.page_size // args.bytes_per_node
    print(f"  Page size: {args.page_size} bytes")
    print(f"  Nodes per page: {nodes_per_page}")
    print(f"  Method: {args.method}")

    # Build layout
    if args.method == "metis":
        node_order, page_id, summary = build_metis_layout(
            edge_index, num_nodes, nodes_per_page, args.metis_partitions
        )
    else:
        node_order, page_id, summary = build_bfs_layout(
            edge_index, num_nodes, nodes_per_page
        )

    # Save layout
    print(f"\nSaving layout to {args.output}...")
    np.savez_compressed(
        args.output,
        node_order=node_order.numpy(),
        page_id=page_id,
        metadata=json.dumps(summary),
    )

    # Print summary
    print("\nLayout summary:")
    print(f"  Pages: {summary['num_pages']:,}")
    if "avg_page_size" in summary:
        print(f"  Avg page size: {summary['avg_page_size']:.1f}")
    if "full_pages" in summary:
        print(f"  Full pages: {summary['full_pages']:,}")
    if "metis_cuts" in summary:
        print(f"  Metis edge cuts: {summary['metis_cuts']:,}")
    print(f"  Intra-page edges: {summary['intra_edge_fraction']:.1%}")

    return 0


if __name__ == "__main__":
    exit(main())
