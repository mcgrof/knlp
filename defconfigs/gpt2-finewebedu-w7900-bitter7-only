#
# GPT-2 FineWebEdu: AdamWPrune bitter7 ONLY at 50% sparsity
# Optimized for W7900 (48GB VRAM)
# Single test to complete the missing run from Oct 29
#
# Tests:
#   1. AdamWPrune bitter7 + state pruning @ 50%
#

# Model Selection - GPT-2 124M on FineWebEdu
CONFIG_MODEL_MODE_SINGLE=y
CONFIG_MODEL_SELECT_GPT2=y

# Enable test matrix mode
CONFIG_TEST_MATRIX_MODE=y

# GPT-2 Configuration
CONFIG_GPT2_MODEL_124M=y
CONFIG_GPT2_DATASET_FINEWEBEDU=y
CONFIG_GPT2_BLOCK_SIZE=1024
CONFIG_GPT2_GRADIENT_ACCUMULATION=4

# Training settings
CONFIG_BATCH_SIZE=16
CONFIG_GPT2_MAX_ITERS=50000
CONFIG_GPT2_EVAL_INTERVAL=500
CONFIG_GPT2_EVAL_SAMPLES=200
CONFIG_GPT2_WARMUP_STEPS=2000
CONFIG_GPT2_DECAY_LR=y
CONFIG_GPT2_MIN_LR="6e-5"
CONFIG_GPT2_FLASH_ATTENTION=y
# Disable torch.compile() for ROCm stability
CONFIG_GPT2_COMPILE=n
CONFIG_GPT2_WEIGHT_TYING=y
CONFIG_GPT2_DROPOUT="0.1"
CONFIG_GPT2_BIAS=y

# Optimizer Configuration - ONLY AdamWPrune bitter7
CONFIG_OPTIMIZER_MODE_SINGLE=y
CONFIG_OPTIMIZER_SELECT_ADAMWPRUNE=y
CONFIG_OPTIMIZER="adamwprune"

# AdamWPrune bitter7 variant ONLY
CONFIG_ADAMWPRUNE_BASE_ADAMWSPAM=y
CONFIG_ADAMWPRUNE_ENABLE_PRUNING=y
CONFIG_ADAMWPRUNE_TARGET_SPARSITY="0.5"
CONFIG_ADAMWPRUNE_BETA1="0.9"
CONFIG_ADAMWPRUNE_BETA2="0.999"
CONFIG_ADAMWPRUNE_WEIGHT_DECAY="0.1"
# Disable all other bitter variants
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER0=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER1=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER2=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER3=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER4=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER5=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER6=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER8=n
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER9=n
# Enable ONLY bitter7
CONFIG_GPT2_ADAMWPRUNE_VARIANT_BITTER7=y
CONFIG_GPT2_ADAMWPRUNE_DEFAULT_VARIANT="bitter7"

# SPAM settings (for AdamWPrune base optimizer)
CONFIG_SPAM_THETA="50.0"
CONFIG_SPAM_INTERVAL=1000
CONFIG_SPAM_WARMUP_STEPS=1000
CONFIG_SPAM_ENABLE_CLIP=y

# Pruning Configuration - state pruning only
CONFIG_PRUNING_MODE_SINGLE=y
CONFIG_PRUNING_SELECT_STATE=y
CONFIG_PRUNING_METHOD="state"
CONFIG_PRUNING_WARMUP=100

# Only 50% sparsity
CONFIG_TARGET_SPARSITY="0.5"
CONFIG_SPARSITY_ENABLE_50=y
CONFIG_SPARSITY_ENABLE_70=n
CONFIG_SPARSITY_ENABLE_90=n
CONFIG_SPARSITY_ENABLE_95=n
CONFIG_SPARSITY_ENABLE_99=n

# Additional training settings
CONFIG_WEIGHT_DECAY="0.1"

# ROCm optimizations
CONFIG_PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
CONFIG_TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=y

# Disable torch.compile() for ROCm stability
CONFIG_COMPILE_MODEL=n

# Tracking - USE THE SAME PROJECT NAME FROM OCT 29 RUN
CONFIG_ENABLE_TRACKIO=y
CONFIG_ENABLE_WANDB=y
CONFIG_TRACKER_PROJECT="tracking-138d5"
CONFIG_TRACKER_RUN_NAME="gpt2_adamwprune_bitter7_state_50"

# Output
CONFIG_OUTPUT_DIR="./results/gpt2-bitter7-only-w7900"
